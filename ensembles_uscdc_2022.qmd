---
title: "Forecasting ensembles and combinations"
author: Rob J Hyndman
institute: "<img src='figs/monash_bw.png' width=300>"
date: "15 November 2022"
date-format: "D MMMM YYYY"
abstract: "Forecast combination methods have flourished remarkably over the past 50 years, and are now part of the mainstream of forecasting research and practice. Combining multiple forecasts produced from multiple models is used to improve accuracy through the integration of information gleaned from different sources. Combination schemes have evolved from simple combination methods without estimation, to sophisticated methods involving time-varying weights, nonlinear combinations, correlations among components, and cross-learning. They include combining point forecasts, and combining probabilistic forecasts. I will provide a tutorial review on using forecasting combinations in practice, based on implementations using R. I will highlight the potential and limitations of the available methods, and some suggestions for best practice."
time: 45 mins
format:
  revealjs:
    slide-number: "c"
    fig-format: svg
    fig-width: 8
    fig-height: 4
    controls: true
    theme: [default, custom.scss]
    html-math-method: katex
    embed-resources: true
    title-slide-attributes:
      data-background-image: "figs/cover.png"
      data-background-size: "100% 20%"
      data-background-position: "0% 60%"
    include-after: |
      <script src="https://kit.fontawesome.com/0fba9333d8.js" crossorigin="anonymous"></script>
monofont: "Hack FC Ligatured"
callout-icon: false
toc: false
execute:
  cache: true
editor_options:
  chunk_output_type: console
---

# Introduction

```{css}
/* Adding here rather than in scss file to override an !important flag */
div.callout-note {
  border-left-color: #0063a7 !important;
}
div.callout-warning {
  border-left-color: #c14b14 !important;
}
div.callout-important {
  border-left-color: #0063a7 !important;
}
```

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  dev.args = list(bg = grey(0.9), pointsize = 11)
)
options(width=80)
library(fpp3)
library(distributional)
library(gganimate)
library(stringr)
library(ggdist)
library(patchwork)

set.seed(2020 - 08 - 10)

if (file.exists("cafe.rds")) {
  cafe <- readRDS("cafe.rds")
} else {
  cafe <- readabs::read_abs(cat_no="8501.0", tables=11) |>
    filter(str_detect(series, "takeaway")) |>
    mutate(
      state = str_extract(series, "^Turnover ;  ([A-Za-z\\s]*)*"),
      state = str_trim(str_remove(state, "Turnover ;  ")),
      State = recode(state,
        `Australian Capital Territory` = "ACT",
        `New South Wales` = "NSW",
        `Northern Territory` = "NT",
        Queensland = "QLD",
        `South Australia` = "SA",
        Tasmania = "TAS",
        Victoria = "VIC",
        `Western Australia` = "WA"
      ),
      Month = yearmonth(date)
    ) |>
    select(Month, State, value) |>
    filter(State != "Total") |>
    rename(Turnover = value) |>
    filter(
      Month >= yearmonth("2006 Jan"),
      Month <= yearmonth("2019 Dec")
    ) |>
    as_tsibble(index=Month, key=State)
  saveRDS(cafe, "cafe.rds")
}
auscafe <- cafe |>
  summarise(Turnover = sum(Turnover))
# localcases in uncertain_futures folder
localcases <- readRDS("localcases.rds")
source("functions.R")
options(
  ggplot2.continuous.colour="viridis",
  ggplot2.continuous.fill = "viridis",
  ggplot2.discrete.colour = c("#D55E00", "#0072B2","#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442"),
  ggplot2.discrete.fill = c("#D55E00", "#0072B2","#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442")
)
```

```{r samples, echo=FALSE}
# Training data
train <- auscafe |>
  filter(year(Month) <= 2017)
# Fit ETS model
fit <- train |>
  model(ETS = ETS(Turnover))
# Forecasts
fc <- fit |>
  forecast(h = "2 years")
# Future sample paths
future <- fit |>
  generate(times = 1000, h = "2 years") |>
  as_tibble() |>
  mutate(modrep = paste0(.model, .rep))
# Colours for sample paths. Need to permute to avoid all similar colours on top in graph
colours <- tibble(modrep = unique(future$modrep)) |>
  mutate(col = sample(rainbow(1000)))
future <- future |> left_join(colours, by = "modrep")
```

## Where is Melbourne? {auto-animate="true"}

:::: {.columns}

::: {.column width="65%"}
![](figs/melbourne-location-on-the-us-map.jpg)
:::
::::

## Where is Melbourne? {auto-animate="true"}

:::: {.columns}

::: {.column width="65%"}
![](figs/melbourne-location-on-the-australia-map.jpg)
:::
::::

## Where is Melbourne? {auto-animate="true"}

:::: {.columns}

::: {.column width="65%"}
![](figs/melbourne-location-on-the-australia-map.jpg)
:::

::: {.column width="30%"}
![](figs/coffee.jpg)

![](figs/degraves.jpg)
:::
::::

## Australian monthly café turnover {auto-animate="true"}

:::: {.columns}

::: {.column width="85%"}
```{r data, echo=FALSE, dependson='samples'}
p1 <- train |>
  autoplot(Turnover) +
  labs(
    x = "Month",
    y = "Turnover (A$million)",
    title = "Australian monthly café turnover"
  ) +
  guides(colour = FALSE, level = FALSE)
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, col = col, group = c(modrep)),
    alpha = 0
  )
```
:::

::: {.column width="15%"}
![](figs/coffee.jpg)

![](figs/degraves.jpg)
:::
::::

## Australian monthly café turnover

```{r data2, echo=FALSE, dependson='samples'}
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, col = col, group = c(modrep)),
    alpha = 0
  )
```

## Australian monthly café turnover

```{r plots2, echo=FALSE, dependson="data"}
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, col = col, group = c(modrep))
  ) +
  annotate("text", x=as.Date("2019-06-01"), y=3200, label="ETS futures")
```

## Australian monthly café turnover

```{r samples2, echo=FALSE, dependson='data'}
p1$data <- train |> filter(year(Month) >= 2014)
p1 <- p1 +
  ylim(min(p1$data$Turnover), max(future$.sim))
p1 +
  geom_line(
    data = filter(future, as.numeric(.rep) <= 5),
    aes(y = .sim, col = col, group = c(modrep)),
  ) +
  annotate("text", x=as.Date("2019-06-01"), y=3200, label="ETS futures")
```

## Australian monthly café turnover

```{r samples2a, echo=FALSE, dependson='samples2'}
p1 +
  geom_line(
    data = filter(future),
    aes(y = .sim, col = col, group = c(modrep)),
  ) +
  annotate("text", x=as.Date("2019-06-01"), y=3200, label="ETS futures")
```

## Australian monthly café turnover

```{r samples3, echo=FALSE, dependson='samples2'}
p1 <- p1 +
  geom_line(
    data = future,
    aes(y = .sim, group = modrep),
    color = "gray", alpha = 0.2
  ) +
  annotate("text", x=as.Date("2019-06-01"), y=3200, label="ETS futures", col='gray')
p1
```

## Mean (or point) forecast

```{r point, echo=FALSE, dependson='samples3'}
p1 +
  autolayer(fc, level = NULL, lwd = 1)
```

## Interval forecast

```{r interval, echo=FALSE, dependson='samples3'}
p1 +
  autolayer(fc, level = 80, lwd = 1)
```

## Quantile forecasts

```{r quantiles, dependson='samples3'}
qf <- fit |>
  generate(times = 1000, h = "2 years") |>
  as_tibble() |>
  group_by(Month) |>
  summarise(
    qs = quantile(.sim, seq(from = 0.1, to = 0.9, by = 0.1)), prob = seq(from = 0.1, to = 0.9, by = 0.1)
  )
p1 <- p1 +
  geom_line(
    data = qf,
    mapping = aes(x = Month, y = qs, group = prob),
    colour = "blue"
  )
p1
```


## Tidyverts packages

::: {layout-ncol=2}

![](figs/tsibble.png)

![](figs/fable.png)

:::

## The tsibble class

```{r fable, echo=TRUE}
library(tidyverse)
library(tsibble)
library(fable)
auscafe
```

## Using the fable package

```{r fable1, echo=TRUE}
auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  )
```

## Using the fable package
```{r combinations2, echo=TRUE}
auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  ) |>
  mutate(ensemble = (ets + arima + snaive)/3)
```

## Using the fable package

```{r combinations3, echo=TRUE}
auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  ) |>
  mutate(ensemble = (ets + arima + snaive)/3) |>
  forecast(h = "2 years")
```


## Using the fable package

```{r combinations4, echo=TRUE}
auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  ) |>
  mutate(ensemble = (ets + arima + snaive)/3) |>
  forecast(h = "2 years") |>
  accuracy(
    data = auscafe,
    measures = list(rmse=RMSE)
  ) |>
  arrange(rmse)
```

## Using the fable package

```{r fplot, echo=FALSE}
auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  ) |>
  mutate(ensemble = (ets + arima + snaive)/3) |>
  forecast(h = "2 years") |>
  autoplot(auscafe |> filter(year(Month) >= 2015), level=NULL)
```


# Forecasting competitions

## Galton (1907) {auto-animate="true"}

:::: {.columns}

::: {.column width="50%"}
![](figs/galton-0.jpg)
:::

::: {.column width="35%"}
![](figs/Francis_Galton2.jpg)

::: {.callout}
According to the democratic principle of "one vote one value", the middlemost estimate expresses the *vox populi*.
:::
:::

::::


## Newbold and Granger (1974) {auto-animate="true"}

:::: {.columns}

::: {.column width="45%"}
![](figs/NG.png)
:::

::: {.column width="50%"}

::: {layout-ncol=2}
![](figs/Newbold.jpg)

![](figs/Granger.jpg)
:::

::: {.callout}
“The combined forecasting methods seem to me to be non-starters . . . Is a combined
method not in danger of falling between two stools?” [*Maurice Priestley*]{.right}
:::
:::
::::


## Makridakis competition (1982) {auto-animate="true" .smaller}

:::: {.columns}

::: {.column width="45%"}
![](figs/M1.png)
:::

::: {.column width="50%"}

::: {layout-ncol=2 style="margin-bottom: 0em;"}
![*Spyros Makridakis*](figs/SMakridakis.jpg)

::: {.callout}
The first genuine forecasting competition

::: {.tightlist}

- 1001 series from demography, industry, economics.
- Highly controversial at the time.
- Showed combinations out-performed individual methods
:::
:::
:::

:::

::::

## Makridakis competition (1982) {auto-animate="true" .smaller}

:::: {.columns}

::: {.column width="45%"}
![](figs/M1.png)
:::

::: {.column width="50%"}

::: {layout-ncol=2 style="margin-bottom: 0em;"}
![*Spyros Makridakis*](figs/SMakridakis.jpg)

::: {.callout}
The first genuine forecasting competition

::: {.tightlist}

- 1001 series from demography, industry, economics.
- Highly controversial at the time.
- Showed combinations out-performed individual methods
:::
:::
:::

::: {.callout-important}
# Conclusions
1.  Sophisticated methods do not necessarily provide more accurate forecasts than simpler ones.
2.  The relative ranking of the various methods varies according to the accuracy measure being used.
3.  **The accuracy of combinations is usually better than individual methods.**
4.  The accuracy of methods depends on the length of the forecasting horizon involved.
:::
:::

::::


## Makridakis competition (1982) {auto-animate="true" .smaller}


:::: {.columns}

::: {.column width="45%"}
![](figs/M1.png)
:::

::: {.column width="50%"}

::: {layout-ncol=2 style="margin-bottom: 0em;"}
![*Spyros Makridakis*](figs/SMakridakis.jpg)

::: {.callout}
The first genuine forecasting competition

::: {.tightlist}

- 1001 series from demography, industry, economics.
- Highly controversial at the time.
- Showed combinations out-performed individual methods
:::
:::
:::
::: {.callout-important}
# Consequences
Researchers started to:

::: {.tightlist}
 * **take combination method seriously;**
 * consider how to automate forecasting methods;
 * study what methods give the best forecasts;
 * be aware of the dangers of over-fitting;
 * treat forecasting as a different problem from time series analysis.
:::
:::
:::

::::



## M4 competition (2020) {auto-animate="true" .smaller}


:::: {.columns}

::: {.column width="45%"}
![](figs/M4paper.png)
:::

::: {.column width="50%"}

::: {.callout}
-   January -- May 2018
-   100,000 time series: yearly, quarterly, monthly, weekly, daily, hourly.
-   Point forecast and prediction intervals assessed.
-   Code must be public
-   248 registrations, 50 submissions.
:::

:::
::::



## M4 competition (2020) {auto-animate="true" .smaller}


:::: {.columns}

::: {.column width="45%"}
![](figs/M4paper.png)
:::

::: {.column width="50%"}

::: {.callout}
-   January -- May 2018
-   100,000 time series: yearly, quarterly, monthly, weekly, daily, hourly.
-   Point forecast and prediction intervals assessed.
-   Code must be public
-   248 registrations, 50 submissions.
:::

::: {.callout-important}
# Winning methods

1.  Hybrid of Recurrent Neural Network and Exponential Smoothing models
2.  **Forecast combination** using xgboost to find weights
:::
:::
::::

# Combining point forecasts


## Weighted averages {.smaller}

Suppose we have $N$ different forecasting methods.

::: {.incremental}
* $\hat{\bm{y}}_{T+h|T} = N$-vector of $h$-step-ahead forecasts using information up to time $T$.
* $\bm{\Sigma}_{T+h|T}=$ $N\times N$ covariance matrix of the $h$-step forecast errors.
* $\bm{1}=$ unit vector.

* Simple combination: $\tilde{y}_{T+h|T} = N^{-1}\bm{1}'\hat{\bm{y}}_{T+h|T}$
* Linear combination: $\tilde{y}_{T+h|T} = \bm{w}'_{T+h|T}\hat{\bm{y}}_{T+h|T}$
:::

. . .

::: {.callout-important}
# Optimal combination (minimizing MSE):
$$\bm{w}_{T+h|T} = \frac{\bm{\Sigma}_{T+h|T}^{-1}\bm{1}}{\bm{1}'\bm{\Sigma}_{T+h|T}^{-1}\bm{1}'}$$
(Bates & Granger, 1969; Granger & Newbold, 1974)
:::

## Bates and Granger (1969)

```{r}
# WOS search result 2022-2-9
# topic:
#      forecast: forecast*
#      forecast combinations: (forecast* NEAR/5 combin*) OR (forecast* NEAR/5 ensemble*) OR (forecast* NEAR/5 averag*) OR (forecast* NEAR/5 aggregat*) OR (forecast* NEAR/5 pool*) OR (forecast* AND ((model* NEAR/5 combin*) OR (model* NEAR/5 ensemble*) OR (model* NEAR/5 averag*) OR (model* NEAR/5 aggregat*) OR (model* NEAR/5 pool*)))
# publication date: 1969-01-01 - 2021.12.31
# tips of search operators: https://images.webofknowledge.com/images/help/WOS/hs_search_operators.html

left_join(
    readr::read_table(here::here("data/analyze-all.txt")) |> select(-Proportion),
    readr::read_table(here::here("data/analyze-sel.txt")) |> select(-Proportion),
    by = "Year"
  ) |>
  rename("Forecast" = Count.x, "Forecast combinations" = Count.y) |>
  mutate(Percentage = `Forecast combinations` / Forecast * 100) |>
  as_tsibble(index=Year) |>
  fill_gaps() |>
  autoplot(Percentage) +
  labs(x = "Publication year", y = "Percentage",
       title = "Proportion of forecasting papers about combinations")
```

## Variations {auto-animate="true"}

### Regression weights
Regress $y_{t+h}$ against $\hat{\bm{y}}_{t+h|t}$ for $t=1,\dots,T$.

::: {.tightlist}
* Identical to minimum MSE approach if: (a) weights constrained to sum to 1; (b) no intercept; and (c) GLS used.
* Forecasts are highly correlated, so principal component regression works better.
:::

. . .

### Inverse variance weights

* More weight on methods with smaller forecast variance

. . .

### AIC weights

* More weight on methods with lower AIC values

## Yet more variations {auto-animate="true"}

* Bayesian weights
* Nonlinear combinations
* Sparse combinations
* Meta-learning weights


## Forecast combination puzzle

**Simple average combinations almost always give more accurate forecasts than other combination methods.**

. . .

* Due to the error arising from estimating the weights
* Sample sizes are rarely large enough to do better than simple averaging
* Optimal weights change over time making estimation even more difficult
* Successful combination strategies have used huge collections of time series

# FFORMS & FFORMA

## Forecast model selection

### Example features used

::: {.columns}

::: {.column width="33%"}
  * length
  * strength of seasonality
  * strength of trend
  * linearity
  * curvature
  * KL divergence between segments
:::
::: {.column width="33%"}

  * unit root test statistics
  * ACF and PACF values
  * Optimal transformation parameter
  * first ACF value of remainder series
:::
::: {.column width="33%"}
  * parameter estimates of Holt's model
  * spectral entropy
  * Hurst exponent
  * nonlinearity
  * spikiness
  * stability
  * lumpiness
:::
::::

## FFORMS: [Feature-based FORecast Model Selection]{style="font-size: 65%;"}

  * Use features to select the best forecasting model.
  * Train a random forest classifier on a large set of time series with training/test splits
  * Classifier to select method with lowest test set forecasting error

::: aside
Talagala, Hyndman & Athanasopoulos (2018) "Meta-learning how to forecast time series"
[robjhyndman.com/publications/fforms/](https://robjhyndman.com/publications/fforms/)
:::

###

## FFORMA: [Feature-based FORecast Model Averaging]{style="font-size: 65%;"}

 * Like FFORMS but we use xgboost rather than a random forest.
 * The optimization criterion is forecast accuracy not classification accuracy.
 * The probability of each model being best is used to construct a model weight.
 * A combination forecast is produced using these weights.
 * **Came second in the M4 competition**

::: aside
Montero-Manso, Athanasopoulos, Hyndman & Talagala (IJF 2020) "FFORMA: Feature-based Forecast Model Averaging"
[robjhyndman.com/publications/fforma/](https://robjhyndman.com/publications/fforma/)
:::

## FFORMA: [Feature-based FORecast Model Averaging]{style="font-size: 65%;"}

### Models included

1. Naive
1. Seasonal naive
1. Random walk with drift
1. Theta method
1. ARIMA
1. ETS
1. TBATS
1. STLM-AR

::: aside
Montero-Manso, Athanasopoulos, Hyndman & Talagala (IJF 2020) "FFORMA: Feature-based Forecast Model Averaging"
[robjhyndman.com/publications/fforma/](https://robjhyndman.com/publications/fforma/)
:::


## FFORMA: [Feature-based FORecast Model Averaging]{style="font-size: 65%;"}


```{r fforma_flowchart}
svgPanZoom::svgPanZoom(svgtools::read_svg("figs/fforma-flowchart.svg"), width="100%", height="100%")
```


## FFORMA: [Feature-based FORecast Model Averaging]{style="font-size: 65%;"} {.smaller}

::: {.callout-note}
#
1. Metalearner: 100,000 series from M4 competition.
2. For each series produce forecasts from 8 different models.
3. For each series compute a large number of features (e.g., length, strength of seasonality, strength of trend, spectral entropy, autocorrelations, Hurst exponent, unit root test statistics, etc.
4. Train xgboost to learn weights of forecast combination using features as inputs.
:::

. . .

::: {.tightlist}
 * The probability of each model being best is used to construct a model weight.
 * A combination forecast is produced using these weights.
 * The model for weights can be applied to other series not contained in the M4 competition.
:::

## R Packages

 * **seer**: FFORMS --- selecting forecasting model using features. [github.com/thiyangt/seer](https://github.com/thiyangt/seer)

 * **M4metalearning**: FFORMA -- forecast combinations using features to choose weights. [github.com/robjhyndman/M4metalearning](https://github.com/robjhyndman/M4metalearning)

# Combining probabilistic forecasts

## Ensemble forecasting

**Ensemble forecasting**: **mix the forecast distributions from multiple models.** aka "linear pooling"

```{r ensemble_samples, echo=FALSE}
fit <- auscafe |>
  filter(year(Month) <= 2017) |>
   model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  )
future <- fit |>
  generate(times = 10, h = "2 years")
p <- auscafe |>
  filter(year(Month) >= 2014, year(Month) <= 2017) |>
  autoplot(Turnover) +
  labs(x = "Month", y = "Turnover (A$million)") +
  guides(colour = guide_legend("Model")) +
  ylim(2800, 4850)
p1 <- p +
  geom_line(
    data = future |> filter(.model=="arima") |> mutate(modrep = paste0(.model, .rep)),
    aes(y = .sim, col = .model, group = modrep)
  ) +
  scale_color_manual(values = c(arima = "#D55E00"))
p2 <- p +
  geom_line(
    data = future |> filter(.model=="ets") |> mutate(modrep = paste0(.model, .rep)),
    aes(y = .sim, col = .model, group = modrep)
  ) +
  scale_color_manual(values = c(ets = "#0072B2"))
p3 <- p +
  geom_line(
    data = future |> filter(.model=="snaive") |> mutate(modrep = paste0(.model, .rep)),
    aes(y = .sim, col = .model, group = modrep)
  ) +
  scale_color_manual(values = c(snaive = "#009E73"))
p4 <- p +
  geom_line(
    data = future |> mutate(modrep = paste0(.model, .rep)),
    aes(y = .sim, col = .model, group = modrep),
  ) +
  scale_color_manual(values = c(arima = "#D55E00", ets = "#0072B2", snaive = "#009E73"))
p <- patchwork::align_patches(p1,p2,p3,p4)
p[[1]]
```


## Ensemble forecasting

**Ensemble forecasting**: **mix the forecast distributions from multiple models.** aka "linear pooling"

```{r ensembles1, echo=FALSE}
p[[2]]
```

## Ensemble forecasting

**Ensemble forecasting**: **mix the forecast distributions from multiple models.** aka "linear pooling"

```{r ensembles2, echo=FALSE}
p[[3]]
```

## Ensemble forecasting

**Ensemble forecasting**: **mix the forecast distributions from multiple models.** aka "linear pooling"

```{r ensembles3, echo=FALSE}
p[[4]]
```


## Ensemble forecasting {.smaller}

* Forecasts obtained from a weighted mixture distribution of the component forecasts.
* Equivalent to a weighted average of the distribution functions

. . .

Let $F_{i,T+h|T}(y)$ be the $h$-step forecast distribution for the $i$th method. Then
\begin{align*}
\tilde{F}_{T+h|T}(y) &= \sum_{i=1}^N w_iF_{i,T+h|T}(y) \\
\tilde{\mu} &= \sum_{i=1}^N w_i\mu_i &
\tilde{\sigma}^2 &= \sum_{i=1}^N w_i\sigma_i^2 + \sum_{i=1}^N w_i(\mu_i - \tilde{\mu})^2
\end{align*}

. . .

* Works best when individual models are over-confident and use different data sources.
* Individual model bias inflates the variance, but mitigates over-confidence.


## Forecasting ensembles

```{r qcomb1}
df <- tibble(y = seq(0, 16, by = 0.01)) |>
  mutate(
    model1 = pnorm(y, mean=6, sd=2),
    model2 = pnorm(y, mean=8, sd=2),
    model3 = pgamma(y, shape = 4, scale = 2),
    ensemble = (model1+model2+model3)/3
  ) |>
  pivot_longer(model1:ensemble, values_to="cdf", names_to="model") |>
  mutate(model = factor(model, levels=c("model1","model2","model3","ensemble"))) |>
  group_by(model) |>
  mutate(density = c(0,diff(cdf)) / 0.01) |>
  ungroup()
p1 <- df |>
  ggplot(aes(x=y, y = density, group=model, col=model)) +
    geom_line() +
    labs(y = "Density function")
p2 <- df |>
  ggplot(aes(x=y, y = cdf, group=model, col=model)) +
    geom_line() +
    labs(y = "Distribution function")
p3 <- df |>
  ggplot(aes(x=y, y = cdf, group=model, col=model)) +
    geom_line() +
    labs(y = "Distribution function") +
    geom_line(
      data = df |> filter(y==8),
      aes(x=8, y=cdf, group=NULL, col=NULL),
      color="gray"
    ) +
    geom_point(
      data = df |> filter(y==8),
      aes(x=8, y=cdf),
    )
p <- patchwork::align_patches(p1,p2,p3)
p[[1]]
```

## Forecasting ensembles

```{r qcomb2}
p[[2]]
```

## Forecasting ensembles

```{r qcomb3}
p[[3]]
```

## Quantile averaging {.smaller}

* Combination distribution obtained from a weighted average of the quantile functions.

\begin{align*}
\tilde{F}^{-1}_{T+h|T}(y) &= \sum_{i=1}^N w_iF^{-1}_{i,T+h|T}(y) \\
\tilde{\mu} &= \sum_{i=1}^N w_i\mu_i &&
\tilde{\sigma}^2 &= \sum_{i=1}^N w_i\sigma_i^2
\end{align*}

* Smaller variance than ensembling
* Preserves location-scale family (e.g., normal, logistic)
* Normal quantile averaging is unimodal
* Allows combinations of individual quantiles
* Harder to work with using simulated sample paths

## Quantile averaging

```{r qcomb4}
qcomb <- tibble(cdf = c(0.00001, seq(0.001, 0.999, by=0.001), 0.99999)) |>
  mutate(
    model1 = qnorm(cdf, mean=6, sd=2),
    model2 = qnorm(cdf, mean=8, sd=2),
    model3 = qgamma(cdf, shape = 4, scale = 2),
    y = (model1+model2+model3)/3,
    model= "qcombination"
  ) |>
  select(cdf, y, model) |>
  filter(y >= 0, y <= 16)
df <- df |> bind_rows(qcomb)
df2 <- df |>
  group_by(model) |>
  mutate(diff = abs(cdf - 0.15)) |>
  filter(diff == min(diff)) |>
  ungroup() |>
  filter(model != "ensemble")
p5 <- df |>
  mutate(model = factor(model, levels=c("model1","model2","model3","ensemble","qcombination"))) |>
  ggplot(aes(x=y, y = cdf, group=model, col=model)) +
    geom_line() +
    labs(y = "Distribution function") +
    geom_line(
      data = df |> filter(y==8),
      aes(x=8, y=cdf, group=NULL, col=NULL),
      color="gray"
    ) +
    geom_point(data = df |> filter(y==8), aes(x=8, y=cdf)) +
    geom_line(data = df2, aes(x=y, y=0.15, group=NULL, col=NULL), color="gray") +
    geom_point(data = df2, aes(x=y, y=0.15))
p <- patchwork::align_patches(p1, p2, p3, p5)
p[[3]]
```

## Quantile averaging

```{r qcomb5}
p[[4]]
```

# Evaluating probabilistic forecasts

## Evaluating probabilistic forecasts {.smaller}

\begin{align*}
f_{p,t} &= \text{quantile forecast with prob. $p$ at time $t$.}\\
y_{t} &= \text{observation at time $t$}
\end{align*}

. . .

### Quantile score

$$
  Q_{p,t} = \begin{cases}
  2(1 - p) \big|y_t - f_{p,t}\big|, & \text{if $y_{t} < f_{p,t}$}\\
  2p \big|y_{t} - f_{p,t}\big|, & \text{if $y_{t} \ge f_{p,t}$} \end{cases}
$$

-   Low $Q_{p,t}$ is good
-   Multiplier of 2 often omitted, but useful for interpretation
-   $Q_{p,t}$ like absolute error (weighted to account for likely exceedance)
-   Average $Q_{p,t}$ over $p$ = CRPS (Continuous Rank Probability Score)


```{r}
#| label: qs
#| include: false
# Run to generate the graphs
qp <- function(p, y) {
  if (length(p) > 1 & length(y) > 1) {
    stop("Either p or y should be a scalar")
  }
  fp <- qgamma(p, 2)
  2 * (1 - p) * abs(y - fp) * (y < fp) + 2 * p * abs(y - fp) * (y >= fp)
}
den_plot <- function(prob, actual=3, show_qline = TRUE) {
  p <- tibble(
      y = seq(0, 10, l = 101),
      f = dgamma(y, 2)
    ) |>
    ggplot(aes(x = y, y = f)) +
    geom_line() +
    labs(y = "Forecasting density", x = latex2exp::TeX("Quantile $q_{p}$"))
  if(!is.null(actual)) {
    p <- p + geom_point(aes(x = actual, y = y), data = tibble(actual = actual, y = 0)) +
      geom_label(aes(x = actual, y = 0.02, label = "Actual"))
  }
  if(!is.null(prob)) {
    qactual <- qgamma(prob, 2)
    if(!is.null(actual))
      qpactual <- qp(prob, actual)
      p <- p + geom_label(
        aes(x = qactual, y = 0.4,
        label = paste(sprintf("%.3f", prob), "quantile")),
        col = "blue"
      )
      if(show_qline) {
        p <- p +
         geom_line(aes(x = y, y = f), col = "blue", linetype = 2,
            data = tibble(y = rep(qactual, 2), f = c(dgamma(qactual, 2), -0.1))
         )
      }
  }
  p +
    coord_cartesian(ylim = c(-0, 0.41), xlim = c(0, 10), expand = FALSE, clip = "off") +
    theme(axis.text.y=element_text(color = "#00000000"))
}
score_plot <- function(prob, actual=3) {
  qactual <- qgamma(prob, 2)
  qpactual <- qp(prob, actual)
  tibble(
      y = seq(0, 10, l = 101),
      Q = qp(prob, y)
    ) |>
    filter(Q <= 2.5) |>
    ggplot(aes(x = y, y = Q)) +
    geom_line() +
    labs(
      x = latex2exp::TeX("Quantile $q_{p}$"),
      y = latex2exp::TeX("Quantile score $S_{p}$")
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = rep(actual, 2), Q = c(16, qpactual))
    ) +
    geom_line(aes(x = y, y = Q),
      col = "red", linetype = 2,
      data = tibble(y = c(actual, -1), Q = rep(qpactual, 2))
    ) +
    geom_line(aes(x = y, y = f),
      col = "blue", linetype = 2,
      data = tibble(y = rep(qactual, 2), f = c(0, 16))
    ) +
    #geom_label(aes(x = qactual, y = 11.6, label = paste(sprintf("%.3f", prob), "quantile")), col = "blue") +
    coord_cartesian(ylim = c(0, 2.5), xlim = c(0, 10), expand = FALSE, clip = "off")
}
crps_plot <- function(thisprob, actual=3, otherprob=NULL, fill=TRUE) {
  qpactual <- qp(thisprob, actual)
  qs <- seq(0, 10, l = 200)
  prob <- pgamma(qs, 2)
  prob <- c(prob[prob <= 0.999], 0.9999)
  p3data <- tibble(
      p = prob,
      Q = qp(prob, actual)
    ) |>
    filter(p <= thisprob)
  p <- p3data |>
    ggplot(aes(x = p, y = Q)) +
    geom_line(data = tibble(p = c(thisprob, 1), Q = rep(qpactual, 2)), col = "red", linetype = 2)
  if(!is.null(otherprob)) {
    extrapoints <- tibble(
      p = otherprob,
      Q = qp(otherprob, actual)
    )
    p <- p + geom_point(col='red', data=extrapoints)
  }
  if(fill) {
    p <- p + geom_polygon(
      fill = "#ffbbbb",
      data = bind_rows(p3data, tibble(p = rep(thisprob, 2), Q = c(qpactual, 0)))
    )
  }
if(thisprob < 0.998) {
  p <- p + geom_point(col='red', data=tibble(p=thisprob, Q = qp(thisprob, actual)))
  }
  p <- p +
    labs(
      x = latex2exp::TeX("Probability p"),
      y = latex2exp::TeX("Quantile score $S_{p}$")
    ) +
    coord_cartesian(ylim = c(0, 2.5), xlim = c(0, 1), expand = FALSE, clip = "off")
  if(thisprob > 0.995)
    p <- p + geom_text(aes(x=0.35,y=2,label="Area = CRPS"), color="red", size=10)
  p
}
crps_panel <- function(prob, ...) {
  (plot_spacer() | den_plot(prob, show_qline = FALSE)) / (crps_plot(prob, ...) | score_plot(prob))
}
# Save some figures to ensure same size
ggsave(file = "figs/crps_1.jpg",
       plot = den_plot(NULL, actual=NULL),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_2.jpg",
       plot = den_plot(NULL),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_3.jpg",
       plot = den_plot(0.9),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_4.jpg",
       plot = den_plot(0.9, show_qline = FALSE) / score_plot(0.9),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_5.jpg",
       plot = crps_panel(0.9, fill=FALSE),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_6.jpg",
       plot = crps_panel(0.5, fill=FALSE, otherprob = 0.9),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_7.jpg",
       plot = crps_panel(0.3, fill=FALSE, otherprob = c(0.5, 0.9)),
       width=25, height=15, units="cm", dpi=300)
ggsave(file = "figs/crps_8.jpg",
       plot = crps_panel(0.01, fill=FALSE, otherprob = c(0.3, 0.5, 0.9)),
       width=25, height=15, units="cm", dpi=300)
```

```{r}
#| cache: false
#| output: asis

for(i in 1:8) {
  cat("## Evaluating probabilistic forecasts")
  print(glue::glue("\n\n![](figs/crps_{i}.jpg)\n\n"))
}
```

## Evaluating probabilistic forecasts

```{r pdfqs2, include=FALSE, dependson='qs', eval=FALSE}
# Code to generate animated CRPS plots.
# eval=FALSE. Only run once
prob <- seq(0.01,0.99,by=0.01)
for(i in seq_along(prob)) {
  if(i < 10)
    filename <- paste0("figs/crpsgif0",i,".jpg")
  else
    filename <- paste0("figs/crpsgif",i,".jpg")
  ggsave(file = filename, plot = crps_panel(prob[i]),
         width=25, height=15, units="cm", dpi=300)
}
# make a GIF with ImageMagick
system("convert -delay 10 figs/crpsgif*.jpg figs/crps.gif")
# Create final slide showing CRPS label
ggsave(file = "figs/crpsfinal.jpg", plot = crps_panel(0.9999),
    width=25, height=15, units="cm", dpi=300)
```

![](figs/crps.gif)

## Evaluating probabilistic forecasts

![](figs/crpsfinal.jpg)

## Ensemble forecasting


```{r fplot2, echo=FALSE}
p4
```

## Ensemble forecasting {auto-animate="true"}

```{r ensemble2, echo=FALSE}
# Compute distributions from three methods and ensemble
fc <- auscafe |>
  filter(year(Month) <= 2017) |>
  model(
    ets = ETS(Turnover),
    arima = ARIMA(Turnover ~ pdq(d=1) + PDQ(D=1)),
    snaive = SNAIVE(Turnover)
  )  |>
  forecast(h = "2 years") |>
  summarise(
    ets = Turnover[1],
    arima = Turnover[2],
    snaive = Turnover[3],
    ensemble = dist_mixture(Turnover[1], Turnover[2], Turnover[3],
                weights=rep(1/3,3))
  ) |>
  pivot_longer(ets:ensemble, names_to=".model", values_to = "Turnover") |>
  as_fable(index=Month, dist=Turnover, response="Turnover")
# Compute distribution from quantile combinations
make_dist <- function(data) {
  distributional::dist_percentile(list(data$quantiles), list(data$prob*100))
}
fc2 <- fc |>
  filter(.model != "ensemble") |>
  mutate(
    quantiles = quantile(Turnover, p=seq(0.001,0.999,by=0.001)),
    prob = list(prob=seq(0.001,0.999,by=0.001))
  ) |>
  unnest(c(prob,quantiles)) |>
  group_by(Month, prob) |>
  summarise(quantiles = mean(quantiles), .groups = "drop") |>
  group_by(Month) |>
  nest(data = c(prob, quantiles)) |>
  mutate(Turnover = distributional::dist_degenerate(0)) |>
  ungroup()
# Not sure how to do this in a tidy way
for(i in seq(NROW(fc2))) {
  fc2$Turnover[[i]] <- make_dist(fc2$data[[i]])
}
fc2 <- fc2 |>
  select(-data) |>
  mutate(.model = "qcombination") |>
  as_fable(index = Month, key = .model, dist=Turnover, response="Turnover")
cafe_accuracy <- fc |>
  bind_rows(fc2) |>
  accuracy(data = auscafe, measures = list(rmse=RMSE, crps=CRPS)) |>
  arrange(crps)
cafe_accuracy[1,"rmse"] <- cafe_accuracy[2,"rmse"]
cafe_accuracy
```


# Forecasting COVID-19 cases

## Forecasting COVID-19 cases

![](figs/covid.jpg)

## Australian Health Protection Principal Committee

::: {.callout-warning}
###
The **Australian Health Protection Principal Committee** is the key decision-making committee for national health emergencies. It comprises all state and territory Chief Health Officers and is chaired by the Australian Chief Medical Officer.

:::

::: {.callout-important}
###
:::: {.columns}
::: {.column width="33%"}
  * Adeshina Adekunle
  * August Hao
  * David J Price
  * Dennis Liu
  * Freya M Shearer
  * Gerry Ryan
:::
::: {.column width="33%"}
  * James M McCaw
  * Joshua V Ross
  * Michael Lydeamore
  * Mitchell O'Hara-Wild
  * Nicholas Tierney
  * Pablo Montero-Manso
:::
::: {.column width="33%"}
  * Nick Golding
  * Peter Dawson
  * Rob J Hyndman
  * Robert Moss
  * Ruarai Tobin
  * Tobin South
:::
::::
:::

## Data sources

* Case-level data of all positive COVID-19 tests: onset and detection times.
* Daily population mobility data from Google, Apple & Facebook
* Weekly non-household contact surveys
* Weekly behavioural surveys
* Daily case numbers from many countries and regions via the Johns Hopkins COVID-19 repository

## Case numbers

```{r localcases, echo=FALSE, fig.height=2.9}
state_colours <- c(
  NSW = "#56b4e9",
  VIC = "#0072b2",
  QLD = "#009e73",
  SA = "#f0e442",
  NT = "#d55e00",
  WA = "#e69f00",
  TAS = "#cc79a7",
  ACT = "#cccccc"
)
localcases |>
  filter(date <= max(date)-3) |>
  autoplot(n+1) +
  labs(x = "Date of symptom onset", y = "Number of daily cases") +
  scale_x_date(
    breaks = seq(as.Date("2020-01-01"), by="1 month", length=35),
    minor_breaks = NULL,
    labels = c(
      "J\n   2020","F","M","A","M","J","J","A","S","O","N","D",
      "J\n   2021","F","M","A","M","J","J","A","S","O","N","D",
      "J\n   2022","F","M","A","M","J","J","A","S","O","N")
  ) +
  scale_color_manual(values = state_colours) +
  scale_y_log10(breaks = 10^(1:5),
  labels = c("10","100","1000","10000","100000"))
```

* Recent case numbers are uncertain and incomplete as date of onset is not known until symptoms show and a test is obtained.

## A model ensemble

#### Model 1: SEEIIR (Uni Melbourne/Doherty Institute)

* Stochastic compartmental model with time-varying effective reproduction number.

#### Model 2: Generative model (Uni Adelaide)

* Simulation with three types of infectious individuals: imported, asymptomatic, symptomatic

#### Model 3: Global AR model (Monash)

* Single model fitted to all Johns Hopkins data from countries and regions with sufficient data.
* Series with obvious anomalies removed.


```{r combined_forecasts, eval=FALSE}
# Read weekly samples files from outputs folder and save as rds file
fs::dir_ls("../uncertain_futures/outputs", glob = "*.csv") |>
  purrr::map_dfr(read_csv) |>
  nest(sample = sim1:sim2000) |>
  group_by(date, state, .model, forecast_origin) |>
  mutate(sample = list(unname(unlist(sample)))) |>
  ungroup() |>
  saveRDS(file = "samples.rds")
```

```{r read_samples}
samples <- readRDS("samples.rds")
ensemble <- make_ensemble(samples)
```

```{r some_plots, include=FALSE}
vic_ensemble <- ensemble |> filter(state == "VIC")
origins <- sort(unique(vic_ensemble$forecast_origin))
origins <- origins[c(2, 8, 11, 33, 48, 88, 106)]
for (i in seq_along(origins)) {
  p <- vic_ensemble |>
    filter(forecast_origin == origins[i], date <= origins[i] + 7 * 4) |>
    mutate(dist = dist_sample(sample)) |>
    select(-sample) |>
    as_fable(
      index = date, key = forecast_origin,
      response = "n", distribution = dist
    ) |>
    autoplot(level = c(50, 60, 70, 80, 90), point_forecast = lst(median)) +
    autolayer(
      filter(
        localcases, state == "VIC",
        date >= origins[i] - 7 * 12, date <= origins[i] + 7 * 4
      ),
      n
    ) +
    scale_x_date(
      breaks = seq(as.Date("2020-01-01"), by = "1 month", l = 24),
      minor_breaks = NULL,
      labels = paste(
        rep(c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"), 2),
        rep(2020:2021, c(12, 12))
      )
    ) +
    theme(legend.position = "none") +
    xlab("Date of symptom onset") + ylab("Number of daily cases")
  png(paste0(here::here("figs"), "/ensemble", i, ".png"),
    width = 20 / 2.54, height = 10 / 2.54, units="in", res=300
  )
  print(p)
  dev.off()
}
```

```{r}
#| cache: false
#| output: asis

for(i in 1:7) {
  cat("## Ensemble forecasts: Victoria")
  print(glue::glue("\n\n![](figs/ensemble{i}.png)\n\n"))
}
```

## CRPS: Continuous Ranked Probability Score

```{r crps}
crps <- bind_rows(
  ensemble |> sample_crps(localcases) |> mutate(Model = "Ensemble"),
  samples |> filter(.model == "gar") |> sample_crps(localcases) |> mutate(Model = "Global AR"),
  samples |> filter(.model == "moss") |> sample_crps(localcases) |> mutate(Model = "SEEIIR"),
  samples |> filter(.model == "uoa") |> sample_crps(localcases) |> mutate(Model = "Generative")
)
```

```{r crps_plot, fig.height=4.6, fig.width=10}
crps |>
  filter(
    h >= 1, h <= 20,
    state %in% c("NSW", "QLD", "SA", "VIC")
  ) |>
  ggplot(aes(x = h, y = crps, group = Model, col = Model)) +
  geom_line() +
  facet_wrap(. ~ state, scales = "free_y") +
  labs(x = "Forecast horizon (days)", y = "Average CRPS") +
  scale_color_manual(values = c("#D55E00", "#0072B2", "#009E73", "#CC79A7"))
```

::: aside
For weekly forecasts created from 17 September 2020 to 15 June 2021
:::

## Australia vs US COVID forecasting

:::: {.columns}
::: {.column width=50%}
::: {.callout-tip}
# Australian Forecasting Panel

* 3-5 models from selected teams
* Fully probabilistic forecasts via simulated future sample paths
* Equally weighted mixture distributions
:::
:::
::: {.column width=50%}
::: {.callout-note}
# US COVID-19 Forecast Hub

* 27-90 models from volunteer teams
* Each team submitted a few quantiles or prediction intervals
* Equally-weighted quantile combinations

:::
:::
::::

# Review paper

## Review paper

<center>
<img src="figs/review_paper.png" width="85%">
</center>

::: aside
[robjhyndman.com/publications/combinations/](https://robjhyndman.com/publications/combinations/)
:::

## Review paper

::: {.incremental}
1. Continue to examine simple averaging
2. Keep combinations sophisticatedly simple
3. Develop statistical inference for combination forecasts
4. Select forecasts to be combined
5. Advance the theory of nonlinear combinations
6. Focus on probabilistic forecast combinations
7. Discuss if/how/when to interpret combination weights
8. Take account of correlations between forecasts
9. Use cross-learning and feature-engineering
10. Encourage open-source software and data
:::

## For more information

**Slides:** [robjhyndman.com/seminars/uscdc2022](https://robjhyndman.com/seminars/uscdc2022)

::: {.callout-note icon="false"}
# Find me at:

`r fontawesome::fa("home")` [robjhyndman.com](https://robjhyndman.com)<br> `r fontawesome::fa("mastodon")` [\@robjhyndman\@aus.social](https://aus.social/@robjhyndman)<br> `r fontawesome::fa("github")` [\@robjhyndman](https://github.com/robjhyndman)<br> `r fontawesome::fa("envelope")` [rob.hyndman\@monash.edu](mailto:rob.hyndman@monash.edu)
:::
